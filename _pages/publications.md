---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

**Preprint**
======
1. <ins>S. Akiyama</ins>, T. Suzuki: Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student Settings and its Superiority to Kernel Methods. [[arXiv]](https://arxiv.org/abs/2205.14818)

International Conference Paper (accepted)
======
1. T. Suzuki, <ins>S. Akiyama</ins>: Benefit of deep learning with non-convex noisy gradient descent: Provable excess risk bound and superiority to kernel methods. International Conference on Learning Representations 2021. (selected as splotlight). [[arXiv]](https://arxiv.org/abs/2012.03224)

2. <ins>S. Akiyama</ins>, T. Suzuki: On Learnability via Gradient Method for Two-Layer ReLU Neural Networks in Teacher-Student Setting. International Conference of Machine Learning 2021. [[arXiv]](https://arxiv.org/abs/2106.06251)
